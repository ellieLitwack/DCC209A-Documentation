# "Library of Bodies" VR Project
An exploration of gender, bodies, and virtual reality by Ellie Litwack

[comment]: <> (A preliminary abstract - replace with final capstone card)

## Abstract 
Using virtual reality, a person can experience a sense of bodily ownership over a virtual avatar. This project will develop first person, 360-degree videos which, when delivered via a virtual reality headset, will cause this experience. Past research has focused on using this effect to understand the physiological basis of transness. In contrast, this project will focus on understanding the relationship between bodies and identities. Emphasis will be placed on the opportunity to use body swapping experiences as part of a self-actuated personal exploration of gender. The experience will be distributed on YouTube 360 to provide a practical means for people questioning their gender identities to try on a variety of possible bodies and to help people understand how others experience their own bodies.

## Project History
### Paper Prototype: 180-degree "Spatial Storyboard"
A normal storyboard is a comic-book like, shot-by-shot sketch of the temporal progression of a piece of media. This spatial storyboard instead explores the spatial path that a viewerâ€™s gaze might follow as they are immersed in this virtual reality experience.
![Layout of story board views][paperPrototype]

### User Feedback Incorporated Prototype
Four users used an initial prototype of the VR experience. Several common themes were present in their feedback. Each of these was addressed to create a user feedback incorporated prototype.

- Video Stability:
Users noticed small amounts of shaking in the video, which was caused by an unsteady camera. A process was developed to correct for this instability. High contrast markers were securely attached to walls in the field of view of the camera. The motion paths of the markers were reconstructed digitally. This was used to "cancel-out" the unsteadiness of the camera. After this effect was applied, users did not notice any video stability issues. Below: Reconstructed paths of high contrast markers.
![High contrast marker paths][markers]

- View Angle:
With the initial prototype, viewers complained that they had to strain their heads in order to get a good view of the virtual body. The pitch of the camera was digitally adjusted by 60 degrees. Despite the fact that this moved the visual location of the virtual body away from the location of the user's actual body, users reported that they felt more immersed after the angle and *believed* that the location of the virtual body was the same as the location of their actual body. Below: The initial view transforms, as shown by the arrows, to bring more of the body into the user's comfortable field of view (FOV).
![initial image][init]
![corrected image][correct]

- Clothing:
Users lost immersion when the location of their clothes did not match the location of the clothes on the virtual body. Now, users will be instructed to wear clothes that are similar to those worn in the video.

### Alpha Build
Several improvements were made between the prototype and the alpha build. A high-quality lighting environment was used to improve the visuals. A mirror was added so the user can see more of the virtual body, resulting in a more thought-provoking experience. Two versions were created, one with long pants and the other with shorts, to accommodate the variety of clothing that users might wear during the experience. Overall, the alpha build represents a final visual product that still lacks audio.
![alpha shorts][shorts]
![alpha jeans][jeans]

### Beta Build
No images are included as no visual changes have taken place since the alpha build. A technical challenge that arose in creating the beta build was rendering the video. This is difficult due to the large amount of time required to process the video. Rendering of one of the two videos was initiated on the lab computer on Tuesday April 24th and is expected to complete by 4:30 PM on Wednesday April 25th assuming that no one shut down the computer during the day. The second video will be rendered after the first is complete.

The main component of the beta build was creating audio to accompany the visual experience. I decided against my initial plan of using a personal narrative of the person in the video because I felt it distracted too much from the already busy experience. After several iterations, I settled on a narration that draws inspiration from the concept of a body scan meditation. The user is asked to ground themselves and focus simply on how their body feels. The user can then reflect on the significance of the experience afterwards.

As the audio cannot be added to the video until rendering has completed, a transcript is below.

#### Transcript
Focus your attention on the souls of your feet. Now, raise your left and hand stretch out your fingertips. Raise your right hand and feel your clenched fist. As you move your hands, feel each part of your body. Finally, drag your hands up your body to trace out the shape of yourself, and then drag them back down. Return your attention to the souls of your feet.

## Author Bio
Ellie Litwack is a mechanical engineering student at the University of Maryland.

[paperPrototype]: https://i.imgur.com/lMmCdsK.jpg
[init]: https://i.imgur.com/XF2Gr3n.jpg
[correct]: https://i.imgur.com/nD3nzBe.jpg
[markers]: https://i.imgur.com/wIMIwSf.png
[shorts]: https://i.imgur.com/YNQjArl.jpg
[jeans]: https://i.imgur.com/IhkVFqJ.jpg
